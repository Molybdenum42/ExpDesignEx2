LINK TO OVERLEAF
https://www.overleaf.com/5139488846tztmskpnwfzq

**Conclusion Issues**
- Swear words are not necessary/sufficient - PROVEN
- DL models outperform ML models
- Oversampling is better due to class imbalance
- Vocab of words used for cyberbullying and their interpretation varies wildly

- word embedding methods have no difference
- no difference between DL models (LSTM generally weaker) against oversampled data

- Task Specific Embedding ????
- TL ????

**Data Issues**
- Twitter data very specifically sourced focusing on keywords which would attract racist and sexist comments (e.g. #notallmen, My Kitchen Rules, Islam Terrorism, etc.)


**Methodology Issues**
Python 2 vs Python 3 (shouldn't be an issue in concept)
TensorFlow vocabulary processor doesn't exist anymore
No train-test split?? Only 5-fold CV - (80/20)
OG People used a Branching CNN instead of a traditional CNN - have changed this as architecture not well-understood
No tuning on ML models
Oversampling done before t/t split

**Replicability Issues**
Table 1 - Vocab size, unknown
Table 2 - Mostly right, questionable methodology on determination of 'swear word'
Table 3 - Baseline ML model not similar at all (even when copying code)

Next Catchup - 19.01, 10am

TODO - Build Embedders for Wiki and Formspring (DG)
TODO - Report (BL/IF)
TODO - Word2Vec (IF) - expect by coming week (Tuesdayish) - got embed dictionary already - check how to get 25/50 dimension?
TODO - run DL models and get results (BL/IF) - BL: Need to add 1 to vocab size for embedders - see glove
TODO - presentation (DG)

TODO - significance testing

TODO - TASK-SPECIFIC - extract embeddings (IF - to understand physical logistics)
TODO - TRANSFER LEARNING (read up on general idea DG - to understand physical logistics)

TODO - presentation (Discuss our plan looking to prove conclusion rather than exact number, what we found so far, things left to do)

