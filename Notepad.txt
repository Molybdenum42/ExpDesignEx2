LINK TO OVERLEAF
https://www.overleaf.com/5139488846tztmskpnwfzq

**Conclusion Issues**
- Swear words are not necessary/sufficient - PROVEN
- DL models outperform ML models
- Oversampling is better due to class imbalance
- Vocab of words used for cyberbullying and their interpretation varies wildly

- word embedding methods have no difference
- no difference between DL models (LSTM generally weaker) against oversampled data

- Task Specific Embedding ????
- TL ????

**Data Issues**
- Twitter data very specifically sourced focusing on keywords which would attract racist and sexist comments (e.g. #notallmen, My Kitchen Rules, Islam Terrorism, etc.)


**Methodology Issues**
Python 2 vs Python 3 (shouldn't be an issue in concept)
TensorFlow vocabulary processor doesn't exist anymore
No train-test split?? Only 5-fold CV - (80/20)
OG People used a Branching CNN instead of a traditional CNN - have changed this as architecture not well-understood
No tuning on ML models
Oversampling done before t/t split

**Replicability Issues**
Table 1 - Vocab size, unknown
Table 2 - Mostly right, questionable methodology on determination of 'swear word'
Table 3 - Baseline ML model not similar at all (even when copying code)

Next Catchup - 19.01, 10am

TODO - Report (BL/IF)
TODO - results generator function (BL)
TODO - significance testing (BL)
TODO - do proper ML (DG)

TODO - TASK-SPECIFIC - extract embeddings (IF - to understand physical logistics)
TODO - TRANSFER LEARNING (read up on general idea DG - to understand physical logistics)

