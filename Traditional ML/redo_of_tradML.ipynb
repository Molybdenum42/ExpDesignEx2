{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "import preprocessor as p"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "models = [ 'svm', 'naive', 'lr', 'random_forest']\n",
    "NO_OF_FOLDS = 10\n",
    "MODEL_TYPE = \"all\"\n",
    "HASH_REMOVE = None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    data = pickle.load(open(filename, 'rb'))\n",
    "    x_text = []\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        if(HASH_REMOVE):\n",
    "            x_text.append(p.tokenize((data[i]['text']).encode('utf-8')))\n",
    "        else:\n",
    "            x_text.append(data[i]['text'])\n",
    "        labels.append(data[i]['label'])\n",
    "    return x_text,labels\n",
    "\n",
    "def get_filename(dataset):\n",
    "    global N_CLASS, HASH_REMOVE\n",
    "    if(dataset==\"twitter\"):\n",
    "        filename = \"../data/twitter_data.pkl\"\n",
    "        N_CLASS = 3\n",
    "        HASH_REMOVE = False\n",
    "    elif(dataset==\"formspring\"):\n",
    "        N_CLASS = 2\n",
    "        filename = \"../data/formspring_data.pkl\"\n",
    "        HASH_REMOVE = False\n",
    "    elif(dataset==\"wiki\"):\n",
    "        N_CLASS = 2\n",
    "        filename = \"../data/wiki_data.pkl\"\n",
    "        HASH_REMOVE = False\n",
    "    return filename"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "#     if(data==\"wiki\"):\n",
    "#         auc = roc_auc_score(y_true,y_pred)\n",
    "#         print('Test ROC AUC: %.3f' %auc)\n",
    "#     print(\":: Confusion Matrix\")\n",
    "#     print(confusion_matrix(y_true, y_pred))\n",
    "#     print(\":: Classification Report\")\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "    return np.array([\n",
    "            precision_score(y_true, y_pred, average=None),\n",
    "            recall_score(y_true, y_pred,  average=None),\n",
    "            f1_score(y_true, y_pred, average=None)])\n",
    "\n",
    "def print_scores(scores):\n",
    "    for i in range(N_CLASS):\n",
    "        if(i!=0):\n",
    "            print(\"Precision Class %d (avg): %0.3f (+/- %0.3f)\" % (i,scores[:, i].mean(), scores[:, i].std() * 2))\n",
    "            print(\"Recall Class %d (avg): %0.3f (+/- %0.3f)\" % (i,scores[:,  N_CLASS+i].mean(), scores[:,N_CLASS+i].std() * 2))\n",
    "            print(\"F1_score Class %d (avg): %0.3f (+/- %0.3f)\" % (i,scores[:, N_CLASS*2+i].mean(), scores[:,  N_CLASS*2+i].std() * 2))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def classification_model(X, Y, model_type):\n",
    "    X, Y = shuffle(X, Y, random_state=42)\n",
    "    print(\"Model Type:\", model_type)\n",
    "    kf = KFold(n_splits=NO_OF_FOLDS)\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        Y = np.asarray(Y)\n",
    "        model = get_model(model_type)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        curr_scores = get_scores(y_test, y_pred)\n",
    "        scores.append(np.hstack(curr_scores))\n",
    "    print_scores(np.array(scores))\n",
    "    return scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_model(m_type):\n",
    "    if m_type == 'lr':\n",
    "        logreg = LogisticRegression(class_weight=\"balanced\")\n",
    "    elif m_type == 'naive':\n",
    "        logreg =  MultinomialNB()\n",
    "    elif m_type == \"random_forest\":\n",
    "        logreg = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "    elif m_type == \"svm\":\n",
    "        logreg = LinearSVC(class_weight=\"balanced\")\n",
    "    else:\n",
    "        print(\"ERROR: Please specify a correst model\")\n",
    "        return None\n",
    "    return logreg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def train(x_text, labels, MODEL_TYPE):\n",
    "\n",
    "    if(WORD):\n",
    "        print(\"Using word based features\")\n",
    "        bow_transformer = CountVectorizer(analyzer=\"word\",max_features = 10000,stop_words='english').fit(x_text)\n",
    "        comments_bow = bow_transformer.transform(x_text)\n",
    "        tfidf_transformer = TfidfTransformer(norm = 'l2').fit(comments_bow)\n",
    "        comments_tfidf = tfidf_transformer.transform(comments_bow)\n",
    "        features = comments_tfidf\n",
    "    else:\n",
    "        print(\"Using char n-grams based features\")\n",
    "        bow_transformer = CountVectorizer(max_features = 10000, ngram_range = (1,2)).fit(x_text)\n",
    "        comments_bow = bow_transformer.transform(x_text)\n",
    "        tfidf_transformer = TfidfTransformer(norm = 'l2').fit(comments_bow)\n",
    "        comments_tfidf = tfidf_transformer.transform(comments_bow)\n",
    "        features = comments_tfidf\n",
    "\n",
    "    if(data == \"twitter\"):\n",
    "        dict1 = {'racism':0,'sexism':1,'none':2}\n",
    "        labels = np.array([dict1[b] for b in labels])\n",
    "\n",
    "    from collections import Counter\n",
    "    print(Counter(labels))\n",
    "\n",
    "    allscores = []\n",
    "\n",
    "    if(MODEL_TYPE != \"all\"):\n",
    "        scores = classification_model(features, labels, MODEL_TYPE)\n",
    "        allscores.append(scores)\n",
    "    else:\n",
    "        for model_type in models:\n",
    "            scores = classification_model(features, labels, model_type)\n",
    "            allscores.append(scores)\n",
    "    return allscores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using char n-grams based features\n",
      "Counter({0: 11997, 1: 776})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.466 (+/- 0.109)\n",
      "Recall Class 1 (avg): 0.503 (+/- 0.122)\n",
      "F1_score Class 1 (avg): 0.483 (+/- 0.104)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.850 (+/- 0.640)\n",
      "Recall Class 1 (avg): 0.015 (+/- 0.015)\n",
      "F1_score Class 1 (avg): 0.030 (+/- 0.028)\n",
      "Model Type: lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Class 1 (avg): 0.410 (+/- 0.100)\n",
      "Recall Class 1 (avg): 0.625 (+/- 0.135)\n",
      "F1_score Class 1 (avg): 0.494 (+/- 0.106)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.777 (+/- 0.174)\n",
      "Recall Class 1 (avg): 0.165 (+/- 0.073)\n",
      "F1_score Class 1 (avg): 0.269 (+/- 0.100)\n"
     ]
    }
   ],
   "source": [
    "data = \"formspring\"\n",
    "WORD =  False\n",
    "x_text, labels = load_data(get_filename(data))\n",
    "print (\"Data loaded!\")\n",
    "formspring_ngram_scores = train(x_text, labels, MODEL_TYPE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using word based features\n",
      "Counter({0: 11997, 1: 776})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.415 (+/- 0.089)\n",
      "Recall Class 1 (avg): 0.525 (+/- 0.132)\n",
      "F1_score Class 1 (avg): 0.463 (+/- 0.100)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.575 (+/- 0.950)\n",
      "Recall Class 1 (avg): 0.013 (+/- 0.029)\n",
      "F1_score Class 1 (avg): 0.025 (+/- 0.055)\n",
      "Model Type: lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Class 1 (avg): 0.407 (+/- 0.078)\n",
      "Recall Class 1 (avg): 0.617 (+/- 0.127)\n",
      "F1_score Class 1 (avg): 0.490 (+/- 0.083)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.733 (+/- 0.232)\n",
      "Recall Class 1 (avg): 0.157 (+/- 0.070)\n",
      "F1_score Class 1 (avg): 0.257 (+/- 0.102)\n"
     ]
    }
   ],
   "source": [
    "data = \"formspring\"\n",
    "WORD = True\n",
    "x_text, labels = load_data(get_filename(data))\n",
    "print (\"Data loaded!\")\n",
    "formspring_unigram_scores = train(x_text, labels, MODEL_TYPE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using char n-grams based features\n",
      "Counter({2: 11036, 1: 3117, 0: 1937})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.786 (+/- 0.055)\n",
      "Recall Class 1 (avg): 0.736 (+/- 0.067)\n",
      "F1_score Class 1 (avg): 0.759 (+/- 0.040)\n",
      "Precision Class 2 (avg): 0.891 (+/- 0.026)\n",
      "Recall Class 2 (avg): 0.896 (+/- 0.020)\n",
      "F1_score Class 2 (avg): 0.894 (+/- 0.013)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.910 (+/- 0.056)\n",
      "Recall Class 1 (avg): 0.455 (+/- 0.089)\n",
      "F1_score Class 1 (avg): 0.605 (+/- 0.082)\n",
      "Precision Class 2 (avg): 0.804 (+/- 0.025)\n",
      "Recall Class 2 (avg): 0.963 (+/- 0.008)\n",
      "F1_score Class 2 (avg): 0.876 (+/- 0.014)\n",
      "Model Type: lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Class 1 (avg): 0.738 (+/- 0.043)\n",
      "Recall Class 1 (avg): 0.772 (+/- 0.075)\n",
      "F1_score Class 1 (avg): 0.754 (+/- 0.043)\n",
      "Precision Class 2 (avg): 0.910 (+/- 0.027)\n",
      "Recall Class 2 (avg): 0.851 (+/- 0.018)\n",
      "F1_score Class 2 (avg): 0.879 (+/- 0.012)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.893 (+/- 0.041)\n",
      "Recall Class 1 (avg): 0.557 (+/- 0.085)\n",
      "F1_score Class 1 (avg): 0.686 (+/- 0.073)\n",
      "Precision Class 2 (avg): 0.842 (+/- 0.033)\n",
      "Recall Class 2 (avg): 0.949 (+/- 0.009)\n",
      "F1_score Class 2 (avg): 0.892 (+/- 0.019)\n"
     ]
    }
   ],
   "source": [
    "data = \"twitter\"\n",
    "WORD = False\n",
    "x_text, labels = load_data(get_filename(data))\n",
    "print (\"Data loaded!\")\n",
    "twitter_ngram_scores = train(x_text, labels, MODEL_TYPE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using word based features\n",
      "Counter({2: 11036, 1: 3117, 0: 1937})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.803 (+/- 0.044)\n",
      "Recall Class 1 (avg): 0.744 (+/- 0.052)\n",
      "F1_score Class 1 (avg): 0.772 (+/- 0.037)\n",
      "Precision Class 2 (avg): 0.893 (+/- 0.023)\n",
      "Recall Class 2 (avg): 0.901 (+/- 0.018)\n",
      "F1_score Class 2 (avg): 0.897 (+/- 0.009)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.904 (+/- 0.035)\n",
      "Recall Class 1 (avg): 0.469 (+/- 0.056)\n",
      "F1_score Class 1 (avg): 0.617 (+/- 0.051)\n",
      "Precision Class 2 (avg): 0.806 (+/- 0.022)\n",
      "Recall Class 2 (avg): 0.963 (+/- 0.007)\n",
      "F1_score Class 2 (avg): 0.877 (+/- 0.011)\n",
      "Model Type: lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Class 1 (avg): 0.752 (+/- 0.045)\n",
      "Recall Class 1 (avg): 0.785 (+/- 0.070)\n",
      "F1_score Class 1 (avg): 0.768 (+/- 0.049)\n",
      "Precision Class 2 (avg): 0.913 (+/- 0.024)\n",
      "Recall Class 2 (avg): 0.860 (+/- 0.015)\n",
      "F1_score Class 2 (avg): 0.886 (+/- 0.008)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.869 (+/- 0.037)\n",
      "Recall Class 1 (avg): 0.648 (+/- 0.077)\n",
      "F1_score Class 1 (avg): 0.742 (+/- 0.058)\n",
      "Precision Class 2 (avg): 0.868 (+/- 0.029)\n",
      "Recall Class 2 (avg): 0.935 (+/- 0.009)\n",
      "F1_score Class 2 (avg): 0.900 (+/- 0.014)\n"
     ]
    }
   ],
   "source": [
    "data = \"twitter\"\n",
    "WORD = True\n",
    "x_text, labels = load_data(get_filename(data))\n",
    "print (\"Data loaded!\")\n",
    "twitter_unigram_scores = train(x_text, labels, MODEL_TYPE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using char n-grams based features\n",
      "Counter({0: 102274, 1: 13590})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.591 (+/- 0.025)\n",
      "Recall Class 1 (avg): 0.823 (+/- 0.020)\n",
      "F1_score Class 1 (avg): 0.688 (+/- 0.017)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.839 (+/- 0.010)\n",
      "Recall Class 1 (avg): 0.554 (+/- 0.028)\n",
      "F1_score Class 1 (avg): 0.667 (+/- 0.021)\n",
      "Model Type: lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Class 1 (avg): 0.602 (+/- 0.023)\n",
      "Recall Class 1 (avg): 0.845 (+/- 0.022)\n",
      "F1_score Class 1 (avg): 0.703 (+/- 0.017)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.886 (+/- 0.013)\n",
      "Recall Class 1 (avg): 0.548 (+/- 0.035)\n",
      "F1_score Class 1 (avg): 0.677 (+/- 0.027)\n"
     ]
    }
   ],
   "source": [
    "data = \"wiki\"\n",
    "WORD = False\n",
    "x_text, labels = load_data(get_filename(data))\n",
    "print (\"Data loaded!\")\n",
    "wiki_ngram_scores = train(x_text, labels, MODEL_TYPE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "Using word based features\n",
      "Counter({0: 102274, 1: 13590})\n",
      "Model Type: svm\n",
      "Precision Class 1 (avg): 0.590 (+/- 0.022)\n",
      "Recall Class 1 (avg): 0.818 (+/- 0.026)\n",
      "F1_score Class 1 (avg): 0.686 (+/- 0.019)\n",
      "Model Type: naive\n",
      "Precision Class 1 (avg): 0.899 (+/- 0.016)\n",
      "Recall Class 1 (avg): 0.522 (+/- 0.036)\n",
      "F1_score Class 1 (avg): 0.660 (+/- 0.027)\n",
      "Model Type: lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Class 1 (avg): 0.620 (+/- 0.027)\n",
      "Recall Class 1 (avg): 0.834 (+/- 0.024)\n",
      "F1_score Class 1 (avg): 0.711 (+/- 0.021)\n",
      "Model Type: random_forest\n",
      "Precision Class 1 (avg): 0.811 (+/- 0.026)\n",
      "Recall Class 1 (avg): 0.663 (+/- 0.022)\n",
      "F1_score Class 1 (avg): 0.729 (+/- 0.021)\n"
     ]
    }
   ],
   "source": [
    "data = \"wiki\"\n",
    "WORD = True\n",
    "x_text, labels = load_data(get_filename(data))\n",
    "print (\"Data loaded!\")\n",
    "wiki_unigram_scores = train(x_text, labels, MODEL_TYPE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "list_of_results = []\n",
    "for res in [formspring_ngram_scores, formspring_unigram_scores,\n",
    "            twitter_ngram_scores, twitter_unigram_scores,\n",
    "            wiki_ngram_scores, wiki_unigram_scores]:\n",
    "    results = {}\n",
    "    for model_n, model_results in enumerate(res):\n",
    "        model_name = models[model_n]\n",
    "        if len(model_results[0]) == 6:\n",
    "            results[model_name] = np.array(model_results)[:, 5].mean()  # == N_CLASS (2) * 2 + 1\n",
    "        else:\n",
    "            results[model_name + \"_racism\"] = np.array(model_results)[:, 7].mean() # == N_CLASS (3)*2 + 1\n",
    "            results[model_name + \"_sexism\"] = np.array(model_results)[:, 8].mean() # == N_CLASS (3)*2 + 2\n",
    "    list_of_results.append(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# getting things into shape\n",
    "import pandas as pd\n",
    "result = pd.DataFrame(list_of_results).stack()\n",
    "index = [(\"Formspring\", \"Character n-grams\", \"SVM\", \"Bully\"),\n",
    "         (\"Formspring\", \"Character n-grams\", \"NB\", \"Bully\"),\n",
    "         (\"Formspring\", \"Character n-grams\", \"LR\", \"Bully\"),\n",
    "         (\"Formspring\", \"Character n-grams\", \"RF\", \"Bully\"),\n",
    "         (\"Formspring\", \"Word unigrams\", \"SVM\", \"Bully\"),\n",
    "         (\"Formspring\", \"Word unigrams\", \"NB\", \"Bully\"),\n",
    "         (\"Formspring\", \"Word unigrams\", \"LR\", \"Bully\"),\n",
    "         (\"Formspring\", \"Word unigrams\", \"RF\", \"Bully\"),\n",
    "         (\"Twitter\", \"Character n-grams\", \"SVM\", \"Racism\"),\n",
    "         (\"Twitter\", \"Character n-grams\", \"NB\", \"Racism\"),\n",
    "         (\"Twitter\", \"Character n-grams\", \"LR\", \"Racism\"),\n",
    "         (\"Twitter\", \"Character n-grams\", \"RF\", \"Racism\"),\n",
    "         (\"Twitter\", \"Word unigrams\", \"SVM\", \"Racism\"),\n",
    "         (\"Twitter\", \"Word unigrams\", \"NB\", \"Racism\"),\n",
    "         (\"Twitter\", \"Word unigrams\", \"LR\", \"Racism\"),\n",
    "         (\"Twitter\", \"Word unigrams\", \"RF\", \"Racism\"),\n",
    "         (\"Twitter\", \"Character n-grams\", \"SVM\", \"Sexism\"),\n",
    "         (\"Twitter\", \"Character n-grams\", \"NB\", \"Sexism\"),\n",
    "         (\"Twitter\", \"Character n-grams\", \"LR\", \"Sexism\"),\n",
    "         (\"Twitter\", \"Character n-grams\", \"RF\", \"Sexism\"),\n",
    "         (\"Twitter\", \"Word unigrams\", \"SVM\", \"Sexism\"),\n",
    "         (\"Twitter\", \"Word unigrams\", \"NB\", \"Sexism\"),\n",
    "         (\"Twitter\", \"Word unigrams\", \"LR\", \"Sexism\"),\n",
    "         (\"Twitter\", \"Word unigrams\", \"RF\", \"Sexism\"),\n",
    "         (\"Wiki\", \"Character n-grams\", \"SVM\", \"Attack\"),\n",
    "         (\"Wiki\", \"Character n-grams\", \"NB\", \"Attack\"),\n",
    "         (\"Wiki\", \"Character n-grams\", \"LR\", \"Attack\"),\n",
    "         (\"Wiki\", \"Character n-grams\", \"RF\", \"Attack\"),\n",
    "         (\"Wiki\", \"Word unigrams\", \"SVM\", \"Attack\"),\n",
    "         (\"Wiki\", \"Word unigrams\", \"NB\", \"Attack\"),\n",
    "         (\"Wiki\", \"Word unigrams\", \"LR\", \"Attack\"),\n",
    "         (\"Wiki\", \"Word unigrams\", \"RF\", \"Attack\")]\n",
    "newindex = pd.MultiIndex.from_tuples(index)\n",
    "result.index = newindex\n",
    "idx = pd.IndexSlice\n",
    "formatted_result = result.unstack(level = [1,2]).loc[:,idx[[\"Character n-grams\", \"Word unigrams\"],[\"LR\", \"SVM\", \"RF\", \"NB\"]]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "formatted_result.to_csv(\"tradml_results_with_their_code_and_data.csv\", index_label=[\"Dataset\", \"Label\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "                  Character n-grams                                \\\n                                 LR       SVM        RF        NB   \nDataset    Label                                                    \nFormspring Bully           0.493913  0.482654  0.269361  0.029881   \nTwitter    Racism          0.605190  0.759149  0.876470  0.893575   \n           Sexism          0.617423  0.771979  0.877226  0.896889   \nWiki       Attack          0.703035  0.687530  0.676726  0.667236   \n\n                  Word unigrams                                \n                             LR       SVM        RF        NB  \nDataset    Label                                               \nFormspring Bully       0.489553  0.462755  0.256930  0.025116  \nTwitter    Racism      0.685532  0.753991  0.892127  0.879111  \n           Sexism      0.741574  0.767808  0.900223  0.885721  \nWiki       Attack      0.710819  0.685770  0.729370  0.659835  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">Character n-grams</th>\n      <th colspan=\"4\" halign=\"left\">Word unigrams</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>LR</th>\n      <th>SVM</th>\n      <th>RF</th>\n      <th>NB</th>\n      <th>LR</th>\n      <th>SVM</th>\n      <th>RF</th>\n      <th>NB</th>\n    </tr>\n    <tr>\n      <th>Dataset</th>\n      <th>Label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Formspring</th>\n      <th>Bully</th>\n      <td>0.493913</td>\n      <td>0.482654</td>\n      <td>0.269361</td>\n      <td>0.029881</td>\n      <td>0.489553</td>\n      <td>0.462755</td>\n      <td>0.256930</td>\n      <td>0.025116</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">Twitter</th>\n      <th>Racism</th>\n      <td>0.605190</td>\n      <td>0.759149</td>\n      <td>0.876470</td>\n      <td>0.893575</td>\n      <td>0.685532</td>\n      <td>0.753991</td>\n      <td>0.892127</td>\n      <td>0.879111</td>\n    </tr>\n    <tr>\n      <th>Sexism</th>\n      <td>0.617423</td>\n      <td>0.771979</td>\n      <td>0.877226</td>\n      <td>0.896889</td>\n      <td>0.741574</td>\n      <td>0.767808</td>\n      <td>0.900223</td>\n      <td>0.885721</td>\n    </tr>\n    <tr>\n      <th>Wiki</th>\n      <th>Attack</th>\n      <td>0.703035</td>\n      <td>0.687530</td>\n      <td>0.676726</td>\n      <td>0.667236</td>\n      <td>0.710819</td>\n      <td>0.685770</td>\n      <td>0.729370</td>\n      <td>0.659835</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"tradml_results_with_their_code_and_data.csv\", header=[0,1], index_col=[0,1])\n",
    "test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}