{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"properML.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1CE55BmFTaHrxAJUu59s288S1HCvpTVqt","authorship_tag":"ABX9TyM4+bHdy1Sfxn4QwBa/NvL2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cQ2NSsOiCyaZ"},"outputs":[],"source":["%%script false --no-raise-error\n","# run this to install things that aren't on colab by default! (comment out the %% line above)\n","!pip install preprocessor\n","!pip install auto-sklearn==0.14.3"]},{"cell_type":"code","source":["import autosklearn.classification\n","import autosklearn.metrics\n","import pandas as pd\n","import numpy as np\n","import pickle\n","\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n","from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, confusion_matrix\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","import preprocessor as p\n","\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import LinearSVC\n","from sklearn.model_selection import KFold\n","from sklearn.linear_model import LogisticRegression"],"metadata":{"id":"4QafznjrFoJP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["data loading functions"],"metadata":{"id":"YWpAxgkJG4cz"}},{"cell_type":"code","source":["basepath = \"/content/drive/MyDrive/DataScienceMaster/Experiment Design/\"\n","\n","# set this true if you want to actually run the AutoML section!\n","run = False"],"metadata":{"id":"Sjw6EmlIHaLn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["twitter_dict = {'racism':1,'sexism':2,'none':0}\n","def load_data(filename):\n","    data = pickle.load(open(filename, 'rb'))\n","    x_text = []\n","    labels = []\n","    for i in range(len(data)):\n","        if(HASH_REMOVE):\n","            x_text.append(p.tokenize((data[i]['text']).encode('utf-8')))\n","        else:\n","            x_text.append(data[i]['text'])\n","        label = data[i]['label']\n","        if N_CLASS == 3:\n","          label = twitter_dict[label]\n","        labels.append(label)\n","    return x_text,labels\n","\n","def get_filename(dataset):\n","    global N_CLASS, HASH_REMOVE\n","    if(dataset==\"twitter\"):\n","        filename = basepath+\"twitter_data.pkl\"\n","        N_CLASS = 3\n","        HASH_REMOVE = False\n","    elif(dataset==\"formspring\"):\n","        N_CLASS = 2\n","        filename = basepath+\"formspring_data.pkl\"\n","        HASH_REMOVE = False\n","    elif(dataset==\"wiki\"):\n","        N_CLASS = 2\n","        filename = basepath+\"wiki_data.pkl\"\n","        HASH_REMOVE = False\n","    return filename\n"],"metadata":{"id":"5fH4cp7KHtpw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_train_test_data(data, labels, datarep=\"char\", split=True):\n","  if datarep == \"char\":\n","    print(\"Using char n-grams based features\")\n","    bow_transformer = CountVectorizer(max_features = 10000, ngram_range = (1,2)).fit(data)\n","    comments_bow = bow_transformer.transform(data)\n","    tfidf_transformer = TfidfTransformer(norm = 'l2').fit(comments_bow)\n","    comments_tfidf = tfidf_transformer.transform(comments_bow)\n","    features = comments_tfidf\n","  elif datarep == \"word\":\n","    print(\"Using word based features\")\n","    bow_transformer = CountVectorizer(analyzer=\"word\",max_features = 10000,stop_words='english').fit(data)\n","    comments_bow = bow_transformer.transform(data)\n","    tfidf_transformer = TfidfTransformer(norm = 'l2').fit(comments_bow)\n","    comments_tfidf = tfidf_transformer.transform(comments_bow)\n","    features = comments_tfidf\n","  else:\n","    print(\"invalid data represenation! Must be either 'char' or 'word'.\")\n","    raise ValueError\n","\n","  if split:\n","    train_x, test_x, train_y, test_y = train_test_split(features, labels, test_size=0.2, random_state=31415, shuffle=True)\n","    return train_x, train_y, test_x, test_y\n","  else:\n","    return features, labels\n","\n","def eval_model(model, x_test, y_test):\n","  y_pred = model.predict(x_test)\n","  y_test = np.array([int(x) for x in y_test])\n","  y_pred = np.array([int(x) for x in y_pred])\n","  return np.array([f1_score(y_test, y_pred, average=None)[1:]])\n"],"metadata":{"id":"KXOKTJOALMxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# do auto-ml!\n","\n","def get_model(train_x, train_y, time_limit=20*60): \n","  automl = autosklearn.classification.AutoSklearnClassifier(\n","      time_left_for_this_task = time_limit,\n","      per_run_time_limit = time_limit//4,\n","      memory_limit = 6000,\n","      metric=autosklearn.metrics.f1_macro,\n","      exclude = {'classifier':[\"mlp\"]},\n","      ensemble_size = 1,\n","      n_jobs = -1      \n","  )\n","  automl.fit(train_x, train_y)\n","  return automl"],"metadata":{"id":"MlnMKHyxQveH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_char = {}"],"metadata":{"id":"1bAaJDHaSMbu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if run:\n","  for dataset in [\"formspring\", \"twitter\", \"wiki\"]:\n","    data, labels = load_data(get_filename(dataset))\n","    print(\"got {} data\".format(dataset))\n","    x_train, y_train, x_test, y_test = get_train_test_data(data, labels, datarep=\"char\")\n","    model = get_model(x_train, y_train)\n","    results = eval_model(model, x_test, y_test)\n","    results_char[dataset] = {\"scores\":results, \"model\":model}\n"],"metadata":{"id":"hcL_fqDusplq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if run:\n","  with open(basepath+\"results_tradml_charrepr.pkl\", \"wb\") as f:\n","    pickle.dump(results_char, f, pickle.HIGHEST_PROTOCOL)\n","else:\n","  results_char = pickle.load(open(basepath+\"results_tradml_charrepr.pkl\", \"rb\"))"],"metadata":{"id":"21zz1xM_RRlB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_word = {}"],"metadata":{"id":"AI5FNcxOSLcU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if run:\n","  for dataset in [\"formspring\", \"twitter\", \"wiki\"]:\n","    data, labels = load_data(get_filename(dataset))\n","    print(\"got {} data\".format(dataset))\n","    x_train, y_train, x_test, y_test = get_train_test_data(data, labels, datarep=\"word\")\n","    model = get_model(x_train, y_train)\n","    results = eval_model(model, x_test, y_test)\n","    results_word[dataset] = {\"scores\":results, \"model\":model}"],"metadata":{"id":"A9g3pZCqxmkj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if run:\n","  with open(basepath+\"results_tradml_wordrepr.pkl\",\"wb\") as f:\n","    pickle.dump(results_word, f, pickle.HIGHEST_PROTOCOL)\n","else:\n","  results_word = pickle.load(open(basepath+\"results_tradml_wordrepr.pkl\", \"rb\"))"],"metadata":{"id":"FwGHXZ7QPAb0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results_char"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m2zNY6kWTIJZ","executionInfo":{"status":"ok","timestamp":1643132009592,"user_tz":-60,"elapsed":8,"user":{"displayName":"Dario Giovannini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS0q4E23_CETbkP8F6HJLD1iEMfbrQIDCxwEpgyg=s64","userId":"10455003058405310729"}},"outputId":"c32b95a3-4bc8-4053-c34b-152f3897eb1f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'formspring': {'model': AutoSklearnClassifier(ensemble_size=1, exclude={'classifier': ['mlp']},\n","                        memory_limit=6000, metric=f1_macro, n_jobs=-1,\n","                        per_run_time_limit=300, time_left_for_this_task=1200),\n","  'scores': array([[0.48201439],\n","         [0.41104294],\n","         [0.44370861]])},\n"," 'twitter': {'model': AutoSklearnClassifier(ensemble_size=1, exclude={'classifier': ['mlp']},\n","                        memory_limit=6000, metric=f1_macro, n_jobs=-1,\n","                        per_run_time_limit=300, time_left_for_this_task=1200),\n","  'scores': array([[0.68287037, 0.7210084 ],\n","         [0.78042328, 0.69529984],\n","         [0.72839506, 0.70792079]])},\n"," 'wiki': {'model': AutoSklearnClassifier(ensemble_size=1, exclude={'classifier': ['mlp']},\n","                        memory_limit=6000, metric=f1_macro, n_jobs=-1,\n","                        per_run_time_limit=300, time_left_for_this_task=1200),\n","  'scores': array([[0.5620438 ],\n","         [0.80297952],\n","         [0.66124827]])}}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["results_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bacbBT_y0BrM","executionInfo":{"status":"ok","timestamp":1643132009592,"user_tz":-60,"elapsed":6,"user":{"displayName":"Dario Giovannini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS0q4E23_CETbkP8F6HJLD1iEMfbrQIDCxwEpgyg=s64","userId":"10455003058405310729"}},"outputId":"afed1068-9326-4a1a-8abb-f6290dac10b7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'formspring': {'model': AutoSklearnClassifier(ensemble_size=1, exclude={'classifier': ['mlp']},\n","                        memory_limit=6000, metric=f1_macro, n_jobs=-1,\n","                        per_run_time_limit=300, time_left_for_this_task=1200),\n","  'scores': array([[0.35950413],\n","         [0.53374233],\n","         [0.42962963]])},\n"," 'twitter': {'model': AutoSklearnClassifier(ensemble_size=1, exclude={'classifier': ['mlp']},\n","                        memory_limit=6000, metric=f1_macro, n_jobs=-1,\n","                        per_run_time_limit=300, time_left_for_this_task=1200),\n","  'scores': array([[0.72922252, 0.81150794],\n","         [0.71957672, 0.66288493],\n","         [0.72436751, 0.72970562]])},\n"," 'wiki': {'model': AutoSklearnClassifier(ensemble_size=1, exclude={'classifier': ['mlp']},\n","                        memory_limit=6000, metric=f1_macro, n_jobs=-1,\n","                        per_run_time_limit=300, time_left_for_this_task=1200),\n","  'scores': array([[0.54405941],\n","         [0.81862197],\n","         [0.6536803 ]])}}"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["for ds in results_char:\n","  print(\"char representation\")\n","  f1 = results_char[ds][\"scores\"][-1]\n","  print(ds, f1)\n","print()\n","for ds in results_word:\n","  print(\"word representation\")\n","  f1 = results_word[ds][\"scores\"][-1]\n","  print(ds, f1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wIApNB13TovX","executionInfo":{"status":"ok","timestamp":1643132411304,"user_tz":-60,"elapsed":229,"user":{"displayName":"Dario Giovannini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS0q4E23_CETbkP8F6HJLD1iEMfbrQIDCxwEpgyg=s64","userId":"10455003058405310729"}},"outputId":"94d8ec75-f24a-4124-cc7c-8c72592cdbc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["char representation\n","formspring [0.44370861]\n","char representation\n","twitter [0.72839506 0.70792079]\n","char representation\n","wiki [0.66124827]\n","\n","word representation\n","formspring [0.42962963]\n","word representation\n","twitter [0.72436751 0.72970562]\n","word representation\n","wiki [0.6536803]\n"]}]},{"cell_type":"code","source":["def cv_model(X, y, model):\n","  X,y = shuffle(X, y, random_state=42)\n","  kf = KFold(n_splits=10)\n","  scores = []\n","  for train_index, test_index in kf.split(X):\n","    y = np.asarray(y)\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = y[train_index], y[test_index]\n","    model.refit(X_train,y_train)\n","    y_pred = model.predict(X_test)\n","    curr_scores = eval_model(model, X_test, y_test)\n","    scores.append(np.hstack(curr_scores))\n","  return scores"],"metadata":{"id":"yrkvyXisYjX-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scoredict = {}\n","\n","for n,resultsdict in enumerate([results_char, results_word]):\n","  repr = \"none\"\n","  if n == 0:\n","    repr = \"char\"\n","  else:\n","    repr = \"word\"\n","  scoredict[repr] = {}\n","  for ds in resultsdict:\n","    orig_f1 = resultsdict[ds][\"scores\"][-1]\n","    model = resultsdict[ds][\"model\"]\n","    modeltype = model.leaderboard()[\"type\"].values[0]\n","    print(\"training {} model on {} data, original test set score: {}\".format(modeltype, ds, [round(x, 3) for x in orig_f1]))\n","\n","    data, labels = load_data(get_filename(ds))\n","    features, labels = get_train_test_data(data, labels, datarep=repr, split=False)\n","    scores = cv_model(features, labels, model)\n","    avgscore = np.mean(scores, axis=0)\n","    print(\"Average CV score: \",np.round(avgscore,3))\n","    if ds != \"twitter\":\n","      scoredict[repr][ds] = {\"model\":modeltype, \"cv_f1score\":avgscore}\n","    else:\n","      scoredict[repr][ds] = {\"model\":modeltype, \"cv_f1score_class1\":avgscore[0], \"cv_f1score_class2\":avgscore[1]}\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vpfCJEbbVuXf","executionInfo":{"status":"ok","timestamp":1643142795711,"user_tz":-60,"elapsed":5822471,"user":{"displayName":"Dario Giovannini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiS0q4E23_CETbkP8F6HJLD1iEMfbrQIDCxwEpgyg=s64","userId":"10455003058405310729"}},"outputId":"66833ffe-bc9f-49e3-ea68-6e834944a1da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training extra_trees model on formspring data, original test set score: [0.444]\n","Using char n-grams based features\n","Average CV score:  [0.488]\n","training sgd model on twitter data, original test set score: [0.728, 0.708]\n","Using char n-grams based features\n","Average CV score:  [0.731 0.724]\n","training sgd model on wiki data, original test set score: [0.661]\n","Using char n-grams based features\n","Average CV score:  [0.662]\n","\n","training extra_trees model on formspring data, original test set score: [0.43]\n","Using word based features\n","Average CV score:  [0.454]\n","training random_forest model on twitter data, original test set score: [0.724, 0.73]\n","Using word based features\n","Average CV score:  [0.756 0.739]\n","training sgd model on wiki data, original test set score: [0.654]\n","Using word based features\n","Average CV score:  [0.654]\n","\n"]}]},{"cell_type":"code","source":["pickle.dump(scoredict, open(basepath+\"cv_results.pkl\", \"wb\"))"],"metadata":{"id":"mL_BQ4z-9Tfz"},"execution_count":null,"outputs":[]}]}