{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ca1fea-86d9-4e99-8f8d-3c4f87ec5a92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cPickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10428/461378751.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cPickle'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cPickle as pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c4c0b04-9707-4fbb-93a4-6b57eb328eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, id_col):\n",
    "    \n",
    "    data = pd.read_csv(path, index_col = id_col)\n",
    "    x_text = data['comment'].fillna(\"\").values\n",
    "    labels = data['attack'].values\n",
    "    return x_text, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d532364-e42a-4042-be17-82d458e6b8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Saved 76628 bytes.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "original = '../data/formspring_data.pkl'\n",
    "destination = \"../data/formspring_data_fixed.pkl\"\n",
    "\n",
    "content = ''\n",
    "outsize = 0\n",
    "with open(original, 'rb') as infile:\n",
    "    content = infile.read()\n",
    "with open(destination, 'wb') as output:\n",
    "    for line in content.splitlines():\n",
    "        outsize += len(line) + 1\n",
    "        output.write(line + str.encode('\\n'))\n",
    "\n",
    "print(\"Done. Saved %s bytes.\" % (len(content) - outsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "618cfe90-f685-49cf-86f9-f30377741a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedWriter name='../data/formspring_data_fixed.pkl'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7cc50fa-6eeb-4756-9ea9-67276d68a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def load_data():\n",
    "    filename = \"../data/formspring_data_fixed.pkl\"\n",
    "    print(\"Loading data from file: \" + filename)\n",
    "    data = pickle.load(open(filename, 'rb'))\n",
    "    x_text = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    for i in range(len(data)):\n",
    "        text = \"\".join(l for l in data[i]['text'] if l not in string.punctuation)\n",
    "        x_text.append((data[i]['text']).encode('utf-8'))\n",
    "        labels.append(data[i]['label'])\n",
    "    return x_text,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a68a06d1-31da-4f71-a186-16f05de3998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file: ../data/formspring_data_fixed.pkl\n"
     ]
    }
   ],
   "source": [
    "x_text, labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "632bc325-32f5-41a9-a2e6-98d4253c0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = [\"character n-grams\", \"word unigrams\"]\n",
    "models = [\"lr\", \"svm\", \"rf\", \"nb\"]\n",
    "n_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c3cc8a5-6ef8-4a2a-8c09-51e020349238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name):\n",
    "    if name == \"lr\":\n",
    "        model = LogisticRegression()\n",
    "    elif name == \"svm\":\n",
    "        model = LinearSVC()\n",
    "    elif name == \"rf\":\n",
    "        model = RandomForestClassifier(n_jobs=-1)\n",
    "    elif name == \"nb\":\n",
    "        model = MultinomialNB()\n",
    "    else:\n",
    "        return None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e90adb2-2424-41b0-9fce-fce9e70dbffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(modelname, features, labels):\n",
    "    model = get_model(modelname)\n",
    "    kfoldcv = KFold(n_splits = n_folds)\n",
    "    scores = []\n",
    "    n = 0\n",
    "    for train_index, test_index in kfoldcv.split(features):\n",
    "        n += 1\n",
    "        print(n)\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        model.fit(X=X_train, y=y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        scores.append(f1)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e016160-3f78-47aa-9e6f-f62f76881a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "character n-grams lr\n",
      "1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10428/3706361259.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmodelname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodelname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mmeanf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeanf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10428/2350215138.py\u001b[0m in \u001b[0;36mtrain_eval\u001b[1;34m(modelname, features, labels)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for rep in representations:\n",
    "    if rep == \"word unigrams\":\n",
    "        transformer = CountVectorizer(analyzer=\"word\", stop_words=\"english\")\n",
    "    else:\n",
    "        transformer = CountVectorizer(analyzer = \"char\", ngram_range=(1,2))\n",
    "        \n",
    "    count_textdata = transformer.fit_transform(x_text)\n",
    "    freq_transfomer = TfidfTransformer()\n",
    "    freq_textdata = freq_transfomer.fit_transform(count_textdata)\n",
    "    features = freq_textdata\n",
    "\n",
    "    scores = []\n",
    "    for modelname in models:\n",
    "        print(rep, modelname)\n",
    "        meanf1 = train_eval(modelname, features, labels)\n",
    "        scores.append(meanf1)\n",
    "\n",
    "    results.append(pd.Series(scores, index=models))\n",
    "\n",
    "df = pd.concat(results, axis=0, keys=representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cc34a24-0203-4754-bd12-384375aa681b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "character n-grams  lr     0.061991\n",
       "                   svm    0.145293\n",
       "                   rf     0.006040\n",
       "                   nb     0.009103\n",
       "word unigrams      lr     0.124307\n",
       "                   svm    0.293884\n",
       "                   rf     0.076190\n",
       "                   nb     0.001183\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf3bc1-77fa-48ea-a0b8-63de6a2929d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name = \"F1_Formspring\"\n",
    "df.to_frame().to_csv(\"results_wiki.csv\", index_label=[\"processing\", \"model\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
