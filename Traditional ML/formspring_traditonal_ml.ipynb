{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ca1fea-86d9-4e99-8f8d-3c4f87ec5a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7cc50fa-6eeb-4756-9ea9-67276d68a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def load_data():\n",
    "    filename = \"../data/formspring_data_fixed.pkl\"\n",
    "    print(\"Loading data from file: \" + filename)\n",
    "    data = pickle.load(open(filename, 'rb'))\n",
    "    x_text = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    for i in range(len(data)):\n",
    "        text = \"\".join(l for l in data[i]['text'] if l not in string.punctuation)\n",
    "        x_text.append((data[i]['text']).encode('utf-8'))\n",
    "        labels.append(data[i]['label'])\n",
    "    return x_text,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a68a06d1-31da-4f71-a186-16f05de3998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file: ../data/formspring_data_fixed.pkl\n"
     ]
    }
   ],
   "source": [
    "x_text, labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "632bc325-32f5-41a9-a2e6-98d4253c0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = [\"character n-grams\", \"word unigrams\"]\n",
    "models = [\"lr\", \"svm\", \"rf\", \"nb\"]\n",
    "n_folds = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3cc8a5-6ef8-4a2a-8c09-51e020349238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(m_type):\n",
    "    if m_type == 'lr':\n",
    "        logreg = LogisticRegression(class_weight=\"balanced\")\n",
    "    elif m_type == 'nb':\n",
    "        logreg =  MultinomialNB()\n",
    "    elif m_type == \"rf\":\n",
    "        logreg = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "    elif m_type == \"svm\":\n",
    "        logreg = LinearSVC(class_weight=\"balanced\")\n",
    "    else:\n",
    "        print(\"ERROR: Please specify a correst model\")\n",
    "        return None\n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4528edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_true, y_pred):\n",
    "#     if(data==\"wiki\"):\n",
    "#         auc = roc_auc_score(y_true,y_pred)\n",
    "#         print('Test ROC AUC: %.3f' %auc)\n",
    "#     print(\":: Confusion Matrix\")\n",
    "#     print(confusion_matrix(y_true, y_pred))\n",
    "#     print(\":: Classification Report\")\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "    return np.array([\n",
    "            precision_score(y_true, y_pred, average=None),\n",
    "            recall_score(y_true, y_pred,  average=None),\n",
    "            f1_score(y_true, y_pred, average=None)])\n",
    "\n",
    "def print_scores(scores):\n",
    "    for i in range(N_CLASS):\n",
    "        if(i!=0):\n",
    "            print(\"Precision Class %d (avg): %0.3f (+/- %0.3f)\" % (i,scores[:, i].mean(), scores[:, i].std() * 2))\n",
    "            print(\"Recall Class %d (avg): %0.3f (+/- %0.3f)\" % (i,scores[:,  N_CLASS+i].mean(), scores[:,N_CLASS+i].std() * 2))\n",
    "            print(\"F1_score Class %d (avg): %0.3f (+/- %0.3f)\" % (i,scores[:, N_CLASS*2+i].mean(), scores[:,  N_CLASS*2+i].std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e90adb2-2424-41b0-9fce-fce9e70dbffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(modelname, features, labels):\n",
    "    model = get_model(modelname)\n",
    "    kfoldcv = KFold(n_splits = n_folds)\n",
    "    scores = []\n",
    "    n = 0\n",
    "    for train_index, test_index in kfoldcv.split(features):\n",
    "        n += 1\n",
    "        print(n)\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = np.array(labels)[train_index], np.array(labels)[test_index]\n",
    "        model.fit(X=X_train, y=y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        f1 = f1_score(y_true, y_pred, average=None)\n",
    "        scores.append(f1)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e016160-3f78-47aa-9e6f-f62f76881a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "character n-grams lr\n",
      "1\n",
      "0.5186567164179106\n",
      "2\n",
      "0.13740458015267176\n",
      "3\n",
      "0.378125\n",
      "4\n",
      "0.2877192982456141\n",
      "5\n",
      "0.06217616580310881\n",
      "6\n",
      "0.23448275862068968\n",
      "7\n",
      "0.21818181818181817\n",
      "8\n",
      "0.3186440677966102\n",
      "9\n",
      "0.175\n",
      "10\n",
      "0.10457516339869281\n",
      "character n-grams svm\n",
      "1\n",
      "0.5352112676056338\n",
      "2\n",
      "0.140625\n",
      "3\n",
      "0.39672131147540984\n",
      "4\n",
      "0.29739776951672864\n",
      "5\n",
      "0.053763440860215055\n",
      "6\n",
      "0.22535211267605632\n",
      "7\n",
      "0.21021021021021022\n",
      "8\n",
      "0.30136986301369867\n",
      "9\n",
      "0.19909502262443438\n",
      "10\n",
      "0.08536585365853658\n",
      "character n-grams rf\n",
      "1\n",
      "0.0\n",
      "2\n",
      "0.0\n",
      "3\n",
      "0.011904761904761906\n",
      "4\n",
      "0.034782608695652174\n",
      "5\n",
      "0.0\n",
      "6\n",
      "0.0\n",
      "7\n",
      "0.0\n",
      "8\n",
      "0.031746031746031744\n",
      "9\n",
      "0.0\n",
      "10\n",
      "0.0\n",
      "character n-grams nb\n",
      "1\n",
      "0.0\n",
      "2\n",
      "0.0\n",
      "3\n",
      "0.05050505050505051\n",
      "4\n",
      "0.033333333333333326\n",
      "5\n",
      "0.0\n",
      "6\n",
      "0.0\n",
      "7\n",
      "0.0\n",
      "8\n",
      "0.0\n",
      "9\n",
      "0.0\n",
      "10\n",
      "0.0\n",
      "word unigrams lr\n",
      "1\n",
      "0.7032967032967032\n",
      "2\n",
      "0.2448979591836735\n",
      "3\n",
      "0.512396694214876\n",
      "4\n",
      "0.44816053511705684\n",
      "5\n",
      "0.057971014492753624\n",
      "6\n",
      "0.4067796610169491\n",
      "7\n",
      "0.3383084577114428\n",
      "8\n",
      "0.5652173913043479\n",
      "9\n",
      "0.34615384615384615\n",
      "10\n",
      "0.21818181818181817\n",
      "word unigrams svm\n",
      "1\n",
      "0.6624203821656052\n",
      "2\n",
      "0.15789473684210525\n",
      "3\n",
      "0.43708609271523174\n",
      "4\n",
      "0.4803149606299212\n",
      "5\n",
      "0.07692307692307693\n",
      "6\n",
      "0.3300970873786408\n",
      "7\n",
      "0.3222222222222222\n",
      "8\n",
      "0.6000000000000001\n",
      "9\n",
      "0.3414634146341463\n",
      "10\n",
      "0.12244897959183673\n",
      "word unigrams rf\n",
      "1\n",
      "0.1256544502617801\n",
      "2\n",
      "0.0\n",
      "3\n",
      "0.13259668508287292\n",
      "4\n",
      "0.20437956204379565\n",
      "5\n",
      "0.0\n",
      "6\n",
      "0.0\n",
      "7\n",
      "0.09999999999999999\n",
      "8\n",
      "0.1142857142857143\n",
      "9\n",
      "0.1702127659574468\n",
      "10\n",
      "0.0\n",
      "word unigrams nb\n",
      "1\n",
      "0.0\n",
      "2\n",
      "0.0\n",
      "3\n",
      "0.011695906432748539\n",
      "4\n",
      "0.0\n",
      "5\n",
      "0.0\n",
      "6\n",
      "0.0\n",
      "7\n",
      "0.0\n",
      "8\n",
      "0.0\n",
      "9\n",
      "0.0\n",
      "10\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for rep in representations:\n",
    "    if rep == \"word unigrams\":\n",
    "        transformer = CountVectorizer(analyzer=\"word\", stop_words=\"english\")\n",
    "    else:\n",
    "        transformer = CountVectorizer(analyzer = \"char\", ngram_range=(1,2))\n",
    "        \n",
    "    count_textdata = transformer.fit_transform(x_text)\n",
    "    freq_transfomer = TfidfTransformer()\n",
    "    freq_textdata = freq_transfomer.fit_transform(count_textdata)\n",
    "    features = freq_textdata\n",
    "\n",
    "    scores = []\n",
    "    for modelname in models:\n",
    "        print(rep, modelname)\n",
    "        meanf1 = train_eval(modelname, features, labels)\n",
    "        scores.append(meanf1)\n",
    "\n",
    "    results.append(pd.Series(scores, index=models))\n",
    "\n",
    "df = pd.concat(results, axis=0, keys=representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc34a24-0203-4754-bd12-384375aa681b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "character n-grams  lr     0.243497\n",
       "                   svm    0.244511\n",
       "                   rf     0.009537\n",
       "                   nb     0.008384\n",
       "word unigrams      lr     0.384136\n",
       "                   svm    0.353087\n",
       "                   rf     0.086623\n",
       "                   nb     0.001170\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf3bc1-77fa-48ea-a0b8-63de6a2929d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name = \"F1_Formspring\"\n",
    "df.to_frame().to_csv(\"results_formspring.csv\", index_label=[\"processing\", \"model\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
