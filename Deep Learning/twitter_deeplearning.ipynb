{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from urllib.parse import urlparse\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import preprocessing as tfkp\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ben\n",
      "[nltk_data]     Lee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def load_data():\n",
    "    filename = \"../data/twitter_data_fixed.pkl\"\n",
    "    print(\"Loading data from file: \" + filename)\n",
    "    data = pickle.load(open(filename, 'rb'))\n",
    "    x_text = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    for i in range(len(data)):\n",
    "        text = \"\".join(l for l in data[i]['text'] if l not in string.punctuation)\n",
    "        x_text.append((data[i]['text']).encode('utf-8'))\n",
    "        labels.append(data[i]['label'])\n",
    "    return x_text,labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def is_url(url):\n",
    "  try:\n",
    "    result = urlparse(url)\n",
    "    return all([result.scheme, result.netloc])\n",
    "  except ValueError:\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# embedding stuff\n",
    "\n",
    "def map_weights(embed_dict, vocab, embed_size): # embed size is embedding dim\n",
    "    vocab_size = len(vocab) + 1\n",
    "    weights = np.zeros((vocab_size, embed_size))\n",
    "\n",
    "    n_missed = 0\n",
    "    words_missed = []\n",
    "    for k,v in vocab.items():\n",
    "        try:\n",
    "            weights[v] = embed_dict[k]  # weights[v] is an index, embed_dict[k] is the list of weights\n",
    "        except:\n",
    "            n_missed += 1\n",
    "            words_missed.append(k)\n",
    "    print(f\"{n_missed} embeddings missed of {vocab_size}\")\n",
    "    return weights, words_missed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file: ../data/twitter_data_fixed.pkl\n"
     ]
    }
   ],
   "source": [
    "x_text, labels_og = load_data()\n",
    "labels, uniques = pd.factorize(labels_og)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Intitial Twitter-Specific Pre-processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "comments = pd.DataFrame({'comment': x_text, 'attack': labels})\n",
    "\n",
    "# decode to UTF-8\n",
    "comments['comment'] = comments['comment'].str.decode(\"utf-8\")\n",
    "\n",
    "# remove missing rows\n",
    "comments['comment'].dropna(inplace=True)\n",
    "\n",
    "# remove usernames\n",
    "comments['comment'] = comments['comment'].str.replace('(\\@\\w+.*?)',\"\", regex=True)\n",
    "\n",
    "# lower case everything\n",
    "comments['comment'] = comments['comment'].str.lower()\n",
    "\n",
    "# remove URLs\n",
    "comments['comment'] = [' '.join(y for y in x.split() if not is_url(y)) for x in comments['comment']]\n",
    "\n",
    "# remove stop words\n",
    "comments['comment'] = comments['comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\n",
    "\n",
    "# traditionally, would also lemmatize but this was not done in the main data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             comment  attack\n0  rt : another bloody instant restaurant week ? ...       0\n1   video peshmerga decimating isis far interesting.       0\n2  oh really ? instant restaurants ? that's shock...       0\n3  rt : good weeks #isis. new front opened #sinja...       0\n4  rt : don’t need femisnsn men carry heavy thing...       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>attack</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rt : another bloody instant restaurant week ? ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>video peshmerga decimating isis far interesting.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>oh really ? instant restaurants ? that's shock...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>rt : good weeks #isis. new front opened #sinja...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>rt : don’t need femisnsn men carry heavy thing...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train-Test Split and Tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "X_train_pretoken, X_midway_pretoken, y_train, y_midway = train_test_split(comments['comment'], comments['attack'], random_state = 42, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dim = 25\n",
    "n_classes = len(np.unique(y_train.values))\n",
    "\n",
    "tokenizer = tfkp.text.Tokenizer(oov_token=\"<UNK>\", filters='!\"$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',)\n",
    "tokenizer.fit_on_texts(X_train_pretoken)\n",
    "\n",
    "convert = lambda x: tfkp.sequence.pad_sequences(tokenizer.texts_to_sequences(x),\n",
    "                                                    maxlen=dim,\n",
    "                                                    padding='post', truncating='post')\n",
    "\n",
    "X_train = convert(X_train_pretoken)\n",
    "X_midway = convert(X_midway_pretoken)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_midway, y_midway, random_state = 42, test_size=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Oversampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reshaping for input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "y_train_onehot = to_categorical(y_train, n_classes)\n",
    "y_val_onehot = to_categorical(y_val, n_classes)\n",
    "y_test_onehot = to_categorical(y_test, n_classes)\n",
    "y_train_over_onehot = to_categorical(y_train_over, n_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Glove Embedding Weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "glove_dict = api.load(\"glove-twitter-200\")\n",
    "glove_weights, glove_words_missed = map_weights(glove_dict, tokenizer.word_index, 200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3093 embeddings missed of 15155\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word2vec Weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
      "3546 embeddings missed of 15155\n"
     ]
    }
   ],
   "source": [
    "word_dict = api.load(\"word2vec-google-news-300\")\n",
    "word2vec_weights, word2vec_words_missed = map_weights(word_dict, tokenizer.word_index, 300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Checks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12872, 25)\n",
      "(26508, 25)\n",
      "(1609, 25)\n",
      "(1609, 25)\n",
      "(12872,)\n",
      "(26508,)\n",
      "(1609,)\n",
      "(1609,)\n",
      "(15155, 200)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_train_over))\n",
    "print(np.shape(X_val))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_train_over))\n",
    "print(np.shape(y_val))\n",
    "print(np.shape(y_test))\n",
    "print(np.shape(y_train_over_onehot))\n",
    "print(np.shape(glove_weights))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 8836, 2: 2503, 1: 1533})\n",
      "Counter({2: 8836, 0: 8836, 1: 8836})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_train_over))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Write Embedders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "\n",
    "random_embedder = Embedding(vocab_size, 200, input_length=dim, trainable=True)\n",
    "glove_embedding = Embedding(vocab_size, 200, embeddings_initializer=initializers.Constant(glove_weights),\n",
    "                            trainable=False)\n",
    "word2vec_embedding = Embedding(vocab_size, 300, embeddings_initializer=initializers.Constant(word2vec_weights),\n",
    "                              trainable=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load DL Models and Run Them"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from DL_models import lstm_keras, cnn_keras, blstm, blstm_atten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "lstm_random = lstm_keras(dim,n_classes,random_embedder)\n",
    "lstm_random_over = lstm_keras(dim,n_classes,random_embedder)\n",
    "lstm_glove = lstm_keras(dim,n_classes,glove_embedding)\n",
    "lstm_glove_over = lstm_keras(dim,n_classes,glove_embedding)\n",
    "lstm_word2vec = lstm_keras(dim,n_classes,word2vec_embedding)\n",
    "lstm_word2vec_over = lstm_keras(dim,n_classes,word2vec_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "blstm_random = blstm(dim_,n_classes,random_embedder)\n",
    "blstm_random_over = blstm(dim,n_classes,random_embedder)\n",
    "blstm_glove = blstm(dim,n_classes,glove_embedding)\n",
    "blstm_glove_over = blstm(dim,n_classes,glove_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "ename": "StagingError",
     "evalue": "Exception encountered when calling layer \"att_layer_1\" (type AttLayer).\n\nin user code:\n\n    File \"G:\\My Drive\\Uni\\Experiment Design\\Ass2\\Deep Learning\\DL_models.py\", line 70, in call  *\n        eij = K.tanh(K.dot(x, self.W))\n    File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py\", line 2125, in dot\n        y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n\n    IndexError: pop index out of range\n\n\nCall arguments received:\n  • x=tf.Tensor(shape=(None, 25, 50), dtype=float32)\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mStagingError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\BENLEE~1\\AppData\\Local\\Temp/ipykernel_14096/1099898443.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#BLSTM and CNN need work\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mblstm_atten_random\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblstm_atten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrandom_embedder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mblstm_atten_random_over\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblstm_atten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membed_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrandom_embedder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mblstm_atten_glove\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblstm_atten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membed_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mglove_embedding\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\My Drive\\Uni\\Experiment Design\\Ass2\\Deep Learning\\DL_models.py\u001B[0m in \u001B[0;36mblstm_atten\u001B[1;34m(embed_size, num_classes, embedder)\u001B[0m\n\u001B[0;32m     85\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mDropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.25\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBidirectional\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mLSTM\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membed_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreturn_sequences\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 87\u001B[1;33m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mAttLayer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     88\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mDropout\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.50\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     89\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0madd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mDense\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnum_classes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'softmax'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    528\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    529\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 530\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    531\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    532\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprevious_value\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    697\u001B[0m       \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint:disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    698\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'ag_error_metadata'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 699\u001B[1;33m           \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mag_error_metadata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    700\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    701\u001B[0m           \u001B[1;32mraise\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mStagingError\u001B[0m: Exception encountered when calling layer \"att_layer_1\" (type AttLayer).\n\nin user code:\n\n    File \"G:\\My Drive\\Uni\\Experiment Design\\Ass2\\Deep Learning\\DL_models.py\", line 70, in call  *\n        eij = K.tanh(K.dot(x, self.W))\n    File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py\", line 2125, in dot\n        y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n\n    IndexError: pop index out of range\n\n\nCall arguments received:\n  • x=tf.Tensor(shape=(None, 25, 50), dtype=float32)\n  • mask=None"
     ]
    }
   ],
   "source": [
    "#BLSTM and CNN need work\n",
    "\n",
    "blstm_atten_random = blstm_atten(dim,n_classes,random_embedder)\n",
    "blstm_atten_random_over = blstm_atten(embed_size,n_classes,random_embedder)\n",
    "blstm_atten_glove = blstm_atten(embed_size,n_classes,glove_embedding)\n",
    "blstm_atten_glove_over = blstm_atten(embed_size,n_classes,glove_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "cnn_random = cnn_keras(dim,n_classes,random_embedder)\n",
    "cnn_random_over = cnn_keras(dim,n_classes,random_embedder)\n",
    "cnn_glove = cnn_keras(dim,n_classes,glove_embedding)\n",
    "cnn_glove_over = cnn_keras(dim,n_classes,glove_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 200)           3031000   \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 25, 200)           0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 21, 128)           128128    \n",
      "                                                                 \n",
      " global_max_pooling1d_8 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,159,515\n",
      "Trainable params: 3,159,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must have the same first dimension, got logits shape [32,3] and labels shape [96]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n (defined at c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py:5113)\n]] [Op:__inference_train_function_18112]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:\nIn[0] sparse_categorical_crossentropy/Reshape_1 (defined at c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py:5109)\t\nIn[1] sparse_categorical_crossentropy/Reshape (defined at c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py:3561)\n\nOperation defined at: (most recent call last)\n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\BENLEE~1\\AppData\\Local\\Temp/ipykernel_14096/2549349438.py\", line 2, in <module>\n>>>     cnn_random.fit(X_train, y_train_onehot, epochs=3, validation_data=(X_val, y_val_onehot))\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 1737, in sparse_categorical_crossentropy\n>>>     return backend.sparse_categorical_crossentropy(\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py\", line 5113, in sparse_categorical_crossentropy\n>>>     res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\BENLEE~1\\AppData\\Local\\Temp/ipykernel_14096/2549349438.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mcnn_random\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mcnn_random\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train_onehot\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_val_onehot\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     56\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     57\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 58\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     59\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     60\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m:  logits and labels must have the same first dimension, got logits shape [32,3] and labels shape [96]\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n (defined at c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py:5113)\n]] [Op:__inference_train_function_18112]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:\nIn[0] sparse_categorical_crossentropy/Reshape_1 (defined at c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py:5109)\t\nIn[1] sparse_categorical_crossentropy/Reshape (defined at c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py:3561)\n\nOperation defined at: (most recent call last)\n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\asyncio\\events.py\", line 80, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n>>>     await self.process_one()\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n>>>     await dispatch(*args)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n>>>     await result\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n>>>     reply_content = await reply_content\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n>>>     return super().run_cell(*args, **kwargs)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"C:\\Users\\BENLEE~1\\AppData\\Local\\Temp/ipykernel_14096/2549349438.py\", line 2, in <module>\n>>>     cnn_random.fit(X_train, y_train_onehot, epochs=3, validation_data=(X_val, y_val_onehot))\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\losses.py\", line 1737, in sparse_categorical_crossentropy\n>>>     return backend.sparse_categorical_crossentropy(\n>>> \n>>>   File \"c:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py\", line 5113, in sparse_categorical_crossentropy\n>>>     res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n>>> "
     ]
    }
   ],
   "source": [
    "cnn_random.summary()\n",
    "cnn_random.fit(X_train, y_train_onehot, epochs=3, validation_data=(X_val, y_val_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_22 (Embedding)    (None, 25, 200)           3031000   \n",
      "                                                                 \n",
      " dropout_146 (Dropout)       (None, 25, 200)           0         \n",
      "                                                                 \n",
      " lstm_61 (LSTM)              (None, 25)                22600     \n",
      "                                                                 \n",
      " dropout_147 (Dropout)       (None, 25)                0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 3)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,053,678\n",
      "Trainable params: 3,053,678\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "403/403 [==============================] - 10s 21ms/step - loss: 0.7019 - accuracy: 0.7216 - val_loss: 0.5702 - val_accuracy: 0.7918\n",
      "Epoch 2/3\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.4336 - accuracy: 0.8525 - val_loss: 0.4568 - val_accuracy: 0.8365\n",
      "Epoch 3/3\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.2662 - accuracy: 0.9172 - val_loss: 0.4901 - val_accuracy: 0.8297\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x20d240e0e50>"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_random.summary()\n",
    "lstm_random.fit(X_train,  y_train_onehot, epochs=3, validation_data=(X_val, y_val_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_23 (Embedding)    (None, None, 200)         3031000   \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, None, 200)         0         \n",
      "                                                                 \n",
      " lstm_63 (LSTM)              (None, 25)                22600     \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 25)                0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 3)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,053,678\n",
      "Trainable params: 22,678\n",
      "Non-trainable params: 3,031,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "403/403 [==============================] - 4s 7ms/step - loss: 0.6508 - accuracy: 0.7509 - val_loss: 0.4919 - val_accuracy: 0.8117\n",
      "Epoch 2/3\n",
      "403/403 [==============================] - 3s 7ms/step - loss: 0.5081 - accuracy: 0.8097 - val_loss: 0.4635 - val_accuracy: 0.8316\n",
      "Epoch 3/3\n",
      "403/403 [==============================] - 3s 6ms/step - loss: 0.4804 - accuracy: 0.8174 - val_loss: 0.4519 - val_accuracy: 0.8229\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x20d31347070>"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_glove.summary()\n",
    "lstm_glove.fit(X_train,  y_train_onehot, epochs=3, validation_data=(X_val, y_val_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 300)         4546500   \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, None, 300)         0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 25)                32600     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 25)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,579,178\n",
      "Trainable params: 32,678\n",
      "Non-trainable params: 4,546,500\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "403/403 [==============================] - 5s 8ms/step - loss: 0.6833 - accuracy: 0.7398 - val_loss: 0.5395 - val_accuracy: 0.8036\n",
      "Epoch 2/3\n",
      "403/403 [==============================] - 3s 7ms/step - loss: 0.5292 - accuracy: 0.7955 - val_loss: 0.4692 - val_accuracy: 0.8191\n",
      "Epoch 3/3\n",
      "403/403 [==============================] - 3s 7ms/step - loss: 0.4868 - accuracy: 0.8113 - val_loss: 0.4640 - val_accuracy: 0.8235\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x25e0dac2c40>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_word2vec.summary()\n",
    "lstm_word2vec.fit(X_train,  y_train_onehot, epochs=3, validation_data=(X_val, y_val_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_20 (Embedding)    (None, 25, 25)            378875    \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 25, 25)            0         \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 50)               10200     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 50)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 389,228\n",
      "Trainable params: 389,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "829/829 [==============================] - 10s 9ms/step - loss: 0.5020 - accuracy: 0.7846 - val_loss: 0.5347 - val_accuracy: 0.8086\n",
      "Epoch 2/3\n",
      "829/829 [==============================] - 7s 8ms/step - loss: 0.1915 - accuracy: 0.9364 - val_loss: 0.5850 - val_accuracy: 0.8204\n",
      "Epoch 3/3\n",
      "829/829 [==============================] - 7s 8ms/step - loss: 0.1209 - accuracy: 0.9613 - val_loss: 0.6508 - val_accuracy: 0.8266\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x20d24100520>"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blstm_random_over.summary()\n",
    "blstm_random_over.fit(X_train_over,  y_train_over_onehot, epochs=3, validation_data=(X_val, y_val_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}