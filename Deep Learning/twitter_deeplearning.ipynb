{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from urllib.parse import urlparse\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import preprocessing as tfkp\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\weetb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def load_data():\n",
    "    filename = \"../data/twitter_data_fixed.pkl\"\n",
    "    print(\"Loading data from file: \" + filename)\n",
    "    data = pickle.load(open(filename, 'rb'))\n",
    "    x_text = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    for i in range(len(data)):\n",
    "        text = \"\".join(l for l in data[i]['text'] if l not in string.punctuation)\n",
    "        x_text.append((data[i]['text']).encode('utf-8'))\n",
    "        labels.append(data[i]['label'])\n",
    "    return x_text,labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def is_url(url):\n",
    "  try:\n",
    "    result = urlparse(url)\n",
    "    return all([result.scheme, result.netloc])\n",
    "  except ValueError:\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# embedding stuff\n",
    "\n",
    "def map_weights(embed_dict, vocab, embed_size): # embed size is embedding dim\n",
    "    vocab_size = len(vocab) + 1\n",
    "    weights = np.zeros((vocab_size, embed_size))\n",
    "\n",
    "    n_missed = 0\n",
    "    words_missed = []\n",
    "    for k,v in vocab.items():\n",
    "        try:\n",
    "            weights[v] = embed_dict[k]  # weights[v] is an index, embed_dict[k] is the list of weights\n",
    "        except:\n",
    "            n_missed += 1\n",
    "            words_missed.append(k)\n",
    "    print(f\"{n_missed} embeddings missed of {vocab_size}\")\n",
    "    return weights, words_missed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file: ../data/twitter_data_fixed.pkl\n"
     ]
    }
   ],
   "source": [
    "x_text, labels_og = load_data()\n",
    "labels, uniques = pd.factorize(labels_og)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Intitial Twitter-Specific Pre-processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "comments = pd.DataFrame({'comment': x_text, 'attack': labels})\n",
    "\n",
    "# decode to UTF-8\n",
    "comments['comment'] = comments['comment'].str.decode(\"utf-8\")\n",
    "\n",
    "# remove missing rows\n",
    "comments['comment'].dropna(inplace=True)\n",
    "\n",
    "# remove usernames\n",
    "comments['comment'] = comments['comment'].str.replace('(\\@\\w+.*?)',\"\", regex=True)\n",
    "\n",
    "# lower case everything\n",
    "comments['comment'] = comments['comment'].str.lower()\n",
    "\n",
    "# remove URLs\n",
    "comments['comment'] = [' '.join(y for y in x.split() if not is_url(y)) for x in comments['comment']]\n",
    "\n",
    "# remove stop words\n",
    "comments['comment'] = comments['comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\n",
    "\n",
    "# traditionally, would also lemmatize but this was not done in the main data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             comment  attack\n0  rt : another bloody instant restaurant week ? ...       0\n1   video peshmerga decimating isis far interesting.       0\n2  oh really ? instant restaurants ? that's shock...       0\n3  rt : good weeks #isis. new front opened #sinja...       0\n4  rt : don’t need femisnsn men carry heavy thing...       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>attack</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rt : another bloody instant restaurant week ? ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>video peshmerga decimating isis far interesting.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>oh really ? instant restaurants ? that's shock...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>rt : good weeks #isis. new front opened #sinja...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>rt : don’t need femisnsn men carry heavy thing...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train-Test Split and Tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "X_train_pretoken, X_midway_pretoken, y_train, y_midway = train_test_split(comments['comment'], comments['attack'], random_state = 42, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dim = 25\n",
    "n_classes = len(np.unique(y_train.values))\n",
    "\n",
    "tokenizer = tfkp.text.Tokenizer(oov_token=\"<UNK>\", filters='!\"$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',)\n",
    "tokenizer.fit_on_texts(X_train_pretoken)\n",
    "\n",
    "convert = lambda x: tfkp.sequence.pad_sequences(tokenizer.texts_to_sequences(x),\n",
    "                                                    maxlen=dim,\n",
    "                                                    padding='post', truncating='post')\n",
    "\n",
    "X_train = convert(X_train_pretoken)\n",
    "X_midway = convert(X_midway_pretoken)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_midway, y_midway, random_state = 42, test_size=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Oversampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reshaping for input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "y_train_onehot = to_categorical(y_train, n_classes)\n",
    "y_val_onehot = to_categorical(y_val, n_classes)\n",
    "y_test_onehot = to_categorical(y_test, n_classes)\n",
    "y_train_over_onehot = to_categorical(y_train_over, n_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Glove Embedding Weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "glove_dict = api.load(\"glove-twitter-200\")\n",
    "glove_weights, glove_words_missed = map_weights(glove_dict, tokenizer.word_index, 200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3093 embeddings missed of 15155\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word2vec Weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=-------------------------------------------------] 3.0% 50.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==------------------------------------------------] 5.1% 85.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====---------------------------------------------] 11.0% 183.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========------------------------------------------] 17.5% 291.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========-----------------------------------------] 19.6% 326.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========----------------------------------------] 21.6% 359.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========---------------------------------------] 23.4% 389.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============--------------------------------------] 25.2% 419.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============-------------------------------------] 27.0% 449.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============------------------------------------] 29.3% 488.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================----------------------------------] 33.0% 548.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================---------------------------------] 35.3% 587.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================-------------------------------] 38.8% 645.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================------------------------------] 41.4% 688.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================----------------------------] 44.8% 745.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================---------------------------] 47.1% 782.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================------------------------] 53.5% 889.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================----------------------] 56.4% 938.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================------------------] 64.9% 1078.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================----------------] 68.1% 1132.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================================---------------] 70.5% 1172.3/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================--------------] 72.7% 1209.2/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================================-------------] 75.5% 1255.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================================-----------] 79.1% 1315.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================================--------] 85.7% 1425.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================================-----] 91.0% 1512.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================================----] 93.2% 1550.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================================--] 97.0% 1613.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================================================-] 99.4% 1652.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3546 embeddings missed of 15155\n"
     ]
    }
   ],
   "source": [
    "word_dict = api.load(\"word2vec-google-news-300\")\n",
    "word2vec_weights, word2vec_words_missed = map_weights(word_dict, tokenizer.word_index, 300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Checks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12872, 25)\n",
      "(26508, 25)\n",
      "(1609, 25)\n",
      "(1609, 25)\n",
      "(12872,)\n",
      "(26508,)\n",
      "(1609,)\n",
      "(1609,)\n",
      "(26508, 3)\n",
      "(15155, 200)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_train_over))\n",
    "print(np.shape(X_val))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_train_over))\n",
    "print(np.shape(y_val))\n",
    "print(np.shape(y_test))\n",
    "print(np.shape(y_train_over_onehot))\n",
    "print(np.shape(glove_weights))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 8836, 2: 2503, 1: 1533})\n",
      "Counter({2: 8836, 0: 8836, 1: 8836})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_train_over))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Write Embedders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "\n",
    "random_embedder = Embedding(vocab_size, 200, input_length=dim, trainable=True)\n",
    "glove_embedding = Embedding(vocab_size, 200, embeddings_initializer=initializers.Constant(glove_weights),\n",
    "                            trainable=False)\n",
    "word2vec_embedding = Embedding(vocab_size, 300, embeddings_initializer=initializers.Constant(word2vec_weights),\n",
    "                              trainable=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load DL Models and Run Them"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'blstm_att' from 'DL_models' (G:\\My Drive\\Uni\\Experiment Design\\Ass2\\Deep Learning\\DL_models.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_26684/906971275.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mDL_models\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mlstm_keras\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcnn_keras\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mblstm\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mblstm_att\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'blstm_att' from 'DL_models' (G:\\My Drive\\Uni\\Experiment Design\\Ass2\\Deep Learning\\DL_models.py)"
     ]
    }
   ],
   "source": [
    "from DL_models import lstm_keras, cnn_keras, blstm, blstm_att"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "lstm_random = lstm_keras(dim,n_classes,random_embedder)\n",
    "lstm_random_over = lstm_keras(dim,n_classes,random_embedder)\n",
    "lstm_glove = lstm_keras(dim,n_classes,glove_embedding)\n",
    "lstm_glove_over = lstm_keras(dim,n_classes,glove_embedding)\n",
    "lstm_word2vec = lstm_keras(dim,n_classes,word2vec_embedding)\n",
    "lstm_word2vec_over = lstm_keras(dim,n_classes,word2vec_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "blstm_random = blstm(dim_,n_classes,random_embedder)\n",
    "blstm_random_over = blstm(dim,n_classes,random_embedder)\n",
    "blstm_glove = blstm(dim,n_classes,glove_embedding)\n",
    "blstm_glove_over = blstm(dim,n_classes,glove_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Exception encountered when calling layer \"att_layer_4\" (type AttLayer).\n\npop index out of range\n\nCall arguments received:\n  • x=tf.Tensor(shape=(None, 25, 50), dtype=float32)\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_26684/2021115814.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mblstm_atten_random\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblstm_atten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrandom_embedder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mblstm_atten_random_over\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblstm_atten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrandom_embedder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mblstm_atten_glove\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblstm_atten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mglove_embedding\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mblstm_atten_glove_over\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblstm_atten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mglove_embedding\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\My Drive\\Uni\\Experiment Design\\Ass2\\Deep Learning\\DL_models.py\u001B[0m in \u001B[0;36mblstm_atten\u001B[1;34m(embed_size, num_classes, embedder)\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    528\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    529\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 530\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    531\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    532\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprevious_value\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\My Drive\\Uni\\Experiment Design\\Ass2\\Deep Learning\\DL_models.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, x, mask)\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: Exception encountered when calling layer \"att_layer_4\" (type AttLayer).\n\npop index out of range\n\nCall arguments received:\n  • x=tf.Tensor(shape=(None, 25, 50), dtype=float32)\n  • mask=None"
     ]
    }
   ],
   "source": [
    "blstm_att_random = blstm_att(dim,n_classes,random_embedder)\n",
    "blstm_att_random_over = blstm_att(dim,n_classes,random_embedder)\n",
    "blstm_att_glove = blstm_att(dim,n_classes,glove_embedding)\n",
    "blstm_att_glove_over = blstm_att(dim,n_classes,glove_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "cnn_random = cnn_keras(dim,n_classes,random_embedder)\n",
    "cnn_random_over = cnn_keras(dim,n_classes,random_embedder)\n",
    "cnn_glove = cnn_keras(dim,n_classes,glove_embedding)\n",
    "cnn_glove_over = cnn_keras(dim,n_classes,glove_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 200)           3031000   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25, 200)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 21, 128)           128128    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,159,515\n",
      "Trainable params: 3,159,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "403/403 [==============================] - 27s 64ms/step - loss: 0.5840 - accuracy: 0.7846 - val_loss: 0.4295 - val_accuracy: 0.8359\n",
      "Epoch 2/3\n",
      "403/403 [==============================] - 25s 62ms/step - loss: 0.3293 - accuracy: 0.8776 - val_loss: 0.4476 - val_accuracy: 0.8322\n",
      "Epoch 3/3\n",
      "403/403 [==============================] - 25s 62ms/step - loss: 0.1859 - accuracy: 0.9361 - val_loss: 0.5039 - val_accuracy: 0.8390\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2146eab59d0>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_random.summary()\n",
    "cnn_random.fit(X_train, y_train_onehot, epochs=3, validation_data=(X_val, y_val_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_28020/3018318150.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mlstm_random\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mlstm_random\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0my_train_onehot\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_val_onehot\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'lstm_random' is not defined"
     ]
    }
   ],
   "source": [
    "lstm_random.summary()\n",
    "lstm_random.fit(X_train,  y_train_onehot, epochs=3, validation_data=(X_val, y_val_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_23 (Embedding)    (None, None, 200)         3031000   \n",
      "                                                                 \n",
      " dropout_150 (Dropout)       (None, None, 200)         0         \n",
      "                                                                 \n",
      " lstm_63 (LSTM)              (None, 25)                22600     \n",
      "                                                                 \n",
      " dropout_151 (Dropout)       (None, 25)                0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 3)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,053,678\n",
      "Trainable params: 22,678\n",
      "Non-trainable params: 3,031,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "403/403 [==============================] - 4s 7ms/step - loss: 0.6508 - accuracy: 0.7509 - val_loss: 0.4919 - val_accuracy: 0.8117\n",
      "Epoch 2/3\n",
      "403/403 [==============================] - 3s 7ms/step - loss: 0.5081 - accuracy: 0.8097 - val_loss: 0.4635 - val_accuracy: 0.8316\n",
      "Epoch 3/3\n",
      "403/403 [==============================] - 3s 6ms/step - loss: 0.4804 - accuracy: 0.8174 - val_loss: 0.4519 - val_accuracy: 0.8229\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x20d31347070>"
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_glove.summary()\n",
    "lstm_glove.fit(X_train,  y_train_onehot, epochs=3, validation_data=(X_val, y_val_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 300)         4546500   \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, None, 300)         0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 25)                32600     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 25)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 3)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,579,178\n",
      "Trainable params: 32,678\n",
      "Non-trainable params: 4,546,500\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "403/403 [==============================] - 5s 8ms/step - loss: 0.6833 - accuracy: 0.7398 - val_loss: 0.5395 - val_accuracy: 0.8036\n",
      "Epoch 2/3\n",
      "403/403 [==============================] - 3s 7ms/step - loss: 0.5292 - accuracy: 0.7955 - val_loss: 0.4692 - val_accuracy: 0.8191\n",
      "Epoch 3/3\n",
      "403/403 [==============================] - 3s 7ms/step - loss: 0.4868 - accuracy: 0.8113 - val_loss: 0.4640 - val_accuracy: 0.8235\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x25e0dac2c40>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_word2vec.summary()\n",
    "lstm_word2vec.fit(X_train,  y_train_onehot, epochs=3, validation_data=(X_val, y_val_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_20 (Embedding)    (None, 25, 25)            378875    \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 25, 25)            0         \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 50)               10200     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 50)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 389,228\n",
      "Trainable params: 389,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "829/829 [==============================] - 10s 9ms/step - loss: 0.5020 - accuracy: 0.7846 - val_loss: 0.5347 - val_accuracy: 0.8086\n",
      "Epoch 2/3\n",
      "829/829 [==============================] - 7s 8ms/step - loss: 0.1915 - accuracy: 0.9364 - val_loss: 0.5850 - val_accuracy: 0.8204\n",
      "Epoch 3/3\n",
      "829/829 [==============================] - 7s 8ms/step - loss: 0.1209 - accuracy: 0.9613 - val_loss: 0.6508 - val_accuracy: 0.8266\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x20d24100520>"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blstm_random_over.summary()\n",
    "blstm_random_over.fit(X_train_over,  y_train_over_onehot, epochs=3, validation_data=(X_val, y_val_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}