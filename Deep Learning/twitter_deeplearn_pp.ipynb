{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from urllib.parse import urlparse\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import preprocessing as tfkp\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ben\n",
      "[nltk_data]     Lee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def load_data():\n",
    "    filename = \"../data/twitter_data_fixed.pkl\"\n",
    "    print(\"Loading data from file: \" + filename)\n",
    "    data = pickle.load(open(filename, 'rb'))\n",
    "    x_text = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    for i in range(len(data)):\n",
    "        text = \"\".join(l for l in data[i]['text'] if l not in string.punctuation)\n",
    "        x_text.append((data[i]['text']).encode('utf-8'))\n",
    "        labels.append(data[i]['label'])\n",
    "    return x_text,labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def is_url(url):\n",
    "  try:\n",
    "    result = urlparse(url)\n",
    "    return all([result.scheme, result.netloc])\n",
    "  except ValueError:\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "# embedding stuff\n",
    "\n",
    "def get_embeddings(dim, dataset):\n",
    "    sep = \" \"\n",
    "    if dataset == \"wiki\":\n",
    "        vector_file = f\"glove_embeddings/glove.6B.{dim}d.txt\"\n",
    "    else:\n",
    "        vector_file = f\"glove_embeddings/glove.twitter.27B.{dim}d.txt\"\n",
    "\n",
    "    print(\"Loading data from file: \" + vector_file)\n",
    "    embed_dict = {}\n",
    "    with open(vector_file, \"r\", encoding=\"utf8\") as file:\n",
    "        for line in file.readlines():\n",
    "            row = line.strip().split(sep)\n",
    "            embed_dict[row[0]] = row[1:]    # word : weights\n",
    "\n",
    "    return embed_dict\n",
    "\n",
    "def map_weights(embed_dict, vocab, embed_size): # embed size is embedding dim\n",
    "    vocab_size = len(vocab) + 1\n",
    "    weights = np.zeros((vocab_size, embed_size))\n",
    "\n",
    "    n_missed = 0\n",
    "    words_missed = []\n",
    "    for k,v in vocab.items():\n",
    "        try:\n",
    "            weights[v] = embed_dict[k]  # weights[v] is an index, embed_dict[k] is the list of weights\n",
    "        except:\n",
    "            n_missed += 1\n",
    "            words_missed.append(k)\n",
    "    print(f\"{n_missed} embeddings missed of {vocab_size}\")\n",
    "    return weights, words_missed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file: ../data/twitter_data_fixed.pkl\n"
     ]
    }
   ],
   "source": [
    "x_text, labels_og = load_data()\n",
    "labels, uniques = pd.factorize(labels_og)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Intitial Twitter-Specific Pre-processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "comments = pd.DataFrame({'comment': x_text, 'attack': labels})\n",
    "\n",
    "# decode to UTF-8\n",
    "comments['comment'] = comments['comment'].str.decode(\"utf-8\")\n",
    "\n",
    "# remove missing rows\n",
    "comments['comment'].dropna(inplace=True)\n",
    "\n",
    "# remove usernames\n",
    "comments['comment'] = comments['comment'].str.replace('(\\@\\w+.*?)',\"\", regex=True)\n",
    "\n",
    "# lower case everything\n",
    "comments['comment'] = comments['comment'].str.lower()\n",
    "\n",
    "# remove URLs\n",
    "comments['comment'] = [' '.join(y for y in x.split() if not is_url(y)) for x in comments['comment']]\n",
    "\n",
    "# remove stop words\n",
    "comments['comment'] = comments['comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')]))\n",
    "\n",
    "# traditionally, would also lemmatize but this was not done in the main data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             comment  attack\n0  rt : another bloody instant restaurant week ? ...       0\n1   video peshmerga decimating isis far interesting.       0\n2  oh really ? instant restaurants ? that's shock...       0\n3  rt : good weeks #isis. new front opened #sinja...       0\n4  rt : don’t need femisnsn men carry heavy thing...       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>attack</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rt : another bloody instant restaurant week ? ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>video peshmerga decimating isis far interesting.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>oh really ? instant restaurants ? that's shock...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>rt : good weeks #isis. new front opened #sinja...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>rt : don’t need femisnsn men carry heavy thing...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train-Test Split and Tokenization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "dim = 25 #Using smaller dimensions due to twitter being heaps smaller"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "X_train_pretoken, X_midway_pretoken, y_train, y_midway = train_test_split(comments['comment'], comments['attack'], random_state = 42, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tokenizer = tfkp.text.Tokenizer(oov_token=\"<UNK>\", filters='!\"$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',)\n",
    "tokenizer.fit_on_texts(X_train_pretoken)\n",
    "\n",
    "convert = lambda x: tfkp.sequence.pad_sequences(tokenizer.texts_to_sequences(x),\n",
    "                                                    maxlen=dim,\n",
    "                                                    padding='post', truncating='post')\n",
    "\n",
    "X_train = convert(X_train_pretoken)\n",
    "X_midway = convert(X_midway_pretoken)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_midway, y_midway, random_state = 42, test_size=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[   3,   66, 2200, ...,    0,    0,    0],\n       [  14,  360,  102, ...,    0,    0,    0],\n       [5131,  259,   38, ...,    0,    0,    0],\n       ...,\n       [ 551, 1966,   24, ...,    0,    0,    0],\n       [  29,  453, 2167, ...,    0,    0,    0],\n       [ 197,  292, 2708, ...,    0,    0,    0]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Oversampling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = oversample.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reshaping for input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "y_train_onehot = to_categorical(y_train, 3)\n",
    "y_val_onehot = to_categorical(y_val, 3)\n",
    "y_test_onehot = to_categorical(y_test, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "y_train_over_onehot = to_categorical(y_train_over, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Glove Embedding Weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "embed_dict = get_embeddings(dim, 'twitter')\n",
    "glove_weights, glove_words_missed = map_weights(embed_dict, tokenizer.word_index, dim)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file: glove_embeddings/glove.twitter.27B.25d.txt\n",
      "3093 embeddings missed of 15155\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n         0.      ],\n       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n         0.      ],\n       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n         0.      ],\n       ...,\n       [-0.2856  ,  0.15567 , -0.37745 , ..., -0.47722 , -0.6626  ,\n        -1.3176  ],\n       [-0.95935 ,  0.032384,  0.46495 , ...,  0.5576  , -0.82383 ,\n         0.49732 ],\n       [-0.70743 ,  0.58029 , -0.43538 , ...,  0.38793 , -0.23645 ,\n        -0.64289 ]])"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Word2vec Weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#space here for word2vec"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Checks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12872, 25)\n",
      "(26508, 25)\n",
      "(1609, 25)\n",
      "(1609, 25)\n",
      "(12872,)\n",
      "(26508,)\n",
      "(1609,)\n",
      "(1609,)\n",
      "(15154, 25)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_train_over))\n",
    "print(np.shape(X_val))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_train_over))\n",
    "print(np.shape(y_val))\n",
    "print(np.shape(y_test))\n",
    "print(np.shape(glove_weights))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26508, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_train_over_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 8836, 2: 2503, 1: 1533})\n",
      "Counter({2: 8836, 0: 8836, 1: 8836})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_train_over))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Write Embedders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "embed_size = dim\n",
    "inp_dim = dim\n",
    "\n",
    "random_embedder = Embedding(vocab_size, embed_size, input_length=inp_dim, trainable=True)\n",
    "glove_embedding = Embedding(vocab_size, embed_size, embeddings_initializer=initializers.Constant(glove_weights),\n",
    "                            trainable=False)\n",
    "#word2vec_embedding = Embedding(vocab_size, embed_size, embeddings_initializer=initializers.Constant(word2vec_weights),\n",
    "#                              trainable=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n         0.      ],\n       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n         0.      ],\n       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n         0.      ],\n       ...,\n       [-0.75731 ,  0.1341  , -0.093333, ...,  0.33833 , -1.7699  ,\n         0.45459 ],\n       [-0.2856  ,  0.15567 , -0.37745 , ..., -0.47722 , -0.6626  ,\n        -1.3176  ],\n       [-0.95935 ,  0.032384,  0.46495 , ...,  0.5576  , -0.82383 ,\n         0.49732 ]])"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_weights\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load DL Models and Run Them"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "from DL_models import lstm_keras, cnn_keras, blstm, blstm_atten\n",
    "\n",
    "n_classes = len(np.unique(y_train.values))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "lstm_random = lstm_keras(embed_size,n_classes,random_embedder)\n",
    "lstm_random_over = lstm_keras(embed_size,n_classes,random_embedder)\n",
    "lstm_glove = lstm_keras(embed_size,n_classes,glove_embedding)\n",
    "lstm_glove_over = lstm_keras(embed_size,n_classes,glove_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "blstm_random = blstm(embed_size,n_classes,random_embedder)\n",
    "blstm_random_over = blstm(embed_size,n_classes,random_embedder)\n",
    "blstm_glove = blstm(embed_size,n_classes,glove_embedding)\n",
    "blstm_glove_over = blstm(embed_size,n_classes,glove_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\BENLEE~1\\AppData\\Local\\Temp/ipykernel_1208/2613454773.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#BLSTM and CNN need work\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mblstm_atten_random\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblstm_atten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membed_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrandom_embedder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[0mblstm_atten_random_over\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblstm_atten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membed_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrandom_embedder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mblstm_atten_glove\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mblstm_atten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membed_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mglove_embedding\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\My Drive\\Uni\\Experiment Design\\Ass2\\Deep Learning\\DL_models.py\u001B[0m in \u001B[0;36mblstm_atten\u001B[1;34m(embed_size, num_classes, embedder)\u001B[0m\n",
      "\u001B[1;32mc:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    528\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    529\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 530\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    531\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    532\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprevious_value\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\sequential.py\u001B[0m in \u001B[0;36madd\u001B[1;34m(self, layer)\u001B[0m\n\u001B[0;32m    220\u001B[0m       \u001B[0moutput_tensor\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput_tensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 222\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    223\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0moutput_tensor\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    224\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuilt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API."
     ]
    }
   ],
   "source": [
    "#BLSTM and CNN need work\n",
    "\n",
    "blstm_atten_random = blstm_atten(embed_size,n_classes,random_embedder)\n",
    "blstm_atten_random_over = blstm_atten(embed_size,n_classes,random_embedder)\n",
    "blstm_atten_glove = blstm_atten(embed_size,n_classes,glove_embedding)\n",
    "blstm_atten_glove_over = blstm_atten(embed_size,n_classes,glove_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"max_pooling1d_26\" (type MaxPooling1D).\n\nNegative dimension size caused by subtracting 35 from 1 for '{{node max_pooling1d_26/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 35, 1, 1], padding=\"VALID\", strides=[1, 35, 1, 1]](max_pooling1d_26/ExpandDims)' with input shapes: [?,1,1,64].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1, 64), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\BENLEE~1\\AppData\\Local\\Temp/ipykernel_1208/4238516101.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mcnn_random\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcnn_keras\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membed_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrandom_embedder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mcnn_random_over\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcnn_keras\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membed_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrandom_embedder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mcnn_glove\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcnn_keras\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membed_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mglove_embedding\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mcnn_glove_over\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcnn_keras\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0membed_size\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mn_classes\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mglove_embedding\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mG:\\My Drive\\Uni\\Experiment Design\\Ass2\\Deep Learning\\DL_models.py\u001B[0m in \u001B[0;36mcnn_keras\u001B[1;34m(embed_size, num_classes, embedder)\u001B[0m\n\u001B[0;32m     37\u001B[0m                   \u001B[0moptimizer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'adam'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     38\u001B[0m                   metrics=['accuracy'])\n\u001B[1;32m---> 39\u001B[1;33m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     40\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    528\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    529\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 530\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    531\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    532\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprevious_value\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\ben lee\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\backend.py\u001B[0m in \u001B[0;36mpool2d\u001B[1;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001B[0m\n\u001B[0;32m   5873\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5874\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mpool_mode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'max'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5875\u001B[1;33m     x = tf.compat.v1.nn.max_pool(\n\u001B[0m\u001B[0;32m   5876\u001B[0m         x, pool_size, strides, padding=padding, data_format=tf_data_format)\n\u001B[0;32m   5877\u001B[0m   \u001B[1;32melif\u001B[0m \u001B[0mpool_mode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'avg'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Exception encountered when calling layer \"max_pooling1d_26\" (type MaxPooling1D).\n\nNegative dimension size caused by subtracting 35 from 1 for '{{node max_pooling1d_26/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 35, 1, 1], padding=\"VALID\", strides=[1, 35, 1, 1]](max_pooling1d_26/ExpandDims)' with input shapes: [?,1,1,64].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1, 64), dtype=float32)"
     ]
    }
   ],
   "source": [
    "cnn_random = cnn_keras(embed_size,n_classes,random_embedder)\n",
    "cnn_random_over = cnn_keras(embed_size,n_classes,random_embedder)\n",
    "cnn_glove = cnn_keras(embed_size,n_classes,glove_embedding)\n",
    "cnn_glove_over = cnn_keras(embed_size,n_classes,glove_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_18 (Embedding)    (None, 25, 25)            378875    \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 25, 25)            0         \n",
      "                                                                 \n",
      " lstm_48 (LSTM)              (None, 25)                5100      \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 25)                0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 3)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 384,053\n",
      "Trainable params: 384,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "403/403 [==============================] - 5s 9ms/step - loss: 0.7288 - accuracy: 0.7167 - val_loss: 0.5899 - val_accuracy: 0.7632\n",
      "Epoch 2/3\n",
      "403/403 [==============================] - 3s 8ms/step - loss: 0.5295 - accuracy: 0.7798 - val_loss: 0.5757 - val_accuracy: 0.7775\n",
      "Epoch 3/3\n",
      "403/403 [==============================] - 3s 7ms/step - loss: 0.4029 - accuracy: 0.8560 - val_loss: 0.5203 - val_accuracy: 0.8129\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x20d317cb9d0>"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_random.summary()\n",
    "lstm_random.fit(X_train,  y_train_onehot, epochs=3, validation_data=(X_val, y_val_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_21 (Embedding)    (None, None, 25)          378875    \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, None, 25)          0         \n",
      "                                                                 \n",
      " lstm_52 (LSTM)              (None, 25)                5100      \n",
      "                                                                 \n",
      " dropout_127 (Dropout)       (None, 25)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 3)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 384,053\n",
      "Trainable params: 5,178\n",
      "Non-trainable params: 378,875\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "403/403 [==============================] - 4s 7ms/step - loss: 0.7556 - accuracy: 0.7040 - val_loss: 0.6403 - val_accuracy: 0.7278\n",
      "Epoch 2/3\n",
      "403/403 [==============================] - 2s 6ms/step - loss: 0.6257 - accuracy: 0.7498 - val_loss: 0.5637 - val_accuracy: 0.7582\n",
      "Epoch 3/3\n",
      "403/403 [==============================] - 2s 5ms/step - loss: 0.5846 - accuracy: 0.7701 - val_loss: 0.5198 - val_accuracy: 0.7750\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x20d2d319910>"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_glove.summary()\n",
    "lstm_glove.fit(X_train,  y_train_onehot, epochs=3, validation_data=(X_val, y_val_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_20 (Embedding)    (None, 25, 25)            378875    \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 25, 25)            0         \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 50)               10200     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 50)                0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 389,228\n",
      "Trainable params: 389,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "829/829 [==============================] - 10s 9ms/step - loss: 0.5020 - accuracy: 0.7846 - val_loss: 0.5347 - val_accuracy: 0.8086\n",
      "Epoch 2/3\n",
      "829/829 [==============================] - 7s 8ms/step - loss: 0.1915 - accuracy: 0.9364 - val_loss: 0.5850 - val_accuracy: 0.8204\n",
      "Epoch 3/3\n",
      "829/829 [==============================] - 7s 8ms/step - loss: 0.1209 - accuracy: 0.9613 - val_loss: 0.6508 - val_accuracy: 0.8266\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x20d24100520>"
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blstm_random_over.summary()\n",
    "blstm_random_over.fit(X_train_over,  y_train_over_onehot, epochs=3, validation_data=(X_val, y_val_onehot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}